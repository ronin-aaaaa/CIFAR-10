"""
ä¸€é”®ç»˜åˆ¶è®­ç»ƒç»“æœå¯¹æ¯”å›¾
è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ä¼˜åŒ–å™¨çš„checkpointå¹¶ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
"""
import os
import glob
import torch
import argparse
import numpy as np
from utils.ops_viz import (
    compare_models, load_and_plot_checkpoint,
    plot_confusion_matrix, plot_learning_rate_schedule,
    visualize_augmentations
)
from utils.ops_io import CIFAR10DataLoader
from utils.ops_al import create_model
from torch.optim.lr_scheduler import CosineAnnealingLR

def plot_all_results(include_extra=True, include_confusion=True, 
                     include_lr_schedule=True, include_augmentation=True,
                     include_optuna=True):
    """è‡ªåŠ¨ç»˜åˆ¶æ‰€æœ‰ç»“æœ
    
    å‚æ•°:
        include_extra: æ˜¯å¦ç”Ÿæˆé¢å¤–çš„å¯è§†åŒ–ï¼ˆæ··æ·†çŸ©é˜µã€å­¦ä¹ ç‡æ›²çº¿ç­‰ï¼‰
        include_confusion: æ˜¯å¦ç”Ÿæˆæ··æ·†çŸ©é˜µ
        include_lr_schedule: æ˜¯å¦ç”Ÿæˆå­¦ä¹ ç‡è°ƒåº¦æ›²çº¿
        include_augmentation: æ˜¯å¦ç”Ÿæˆæ•°æ®å¢å¼ºå¯è§†åŒ–
        include_optuna: æ˜¯å¦ç”ŸæˆOptunaè°ƒå‚ç»“æœå¯è§†åŒ–
    """
    print("="*60)
    print("è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒç»“æœå¯¹æ¯”å›¾")
    print("="*60)
    
    # æŸ¥æ‰¾æ‰€æœ‰ä¼˜åŒ–å™¨çš„checkpoint
    checkpoint_dirs = glob.glob('checkpoints_*')
    
    if not checkpoint_dirs:
        print("\næœªæ‰¾åˆ°ä¼˜åŒ–å™¨è®­ç»ƒç»“æœç›®å½• (checkpoints_*)")
        print("è¯·å…ˆè¿è¡Œ: python run_results.py --optimizer all")
        return
    
    checkpoint_paths = []
    labels = []
    
    for dir_name in sorted(checkpoint_dirs):
        best_model_path = os.path.join(dir_name, 'best_model.pth')
        if os.path.exists(best_model_path):
            checkpoint_paths.append(best_model_path)
            # ä»ç›®å½•åæå–ä¼˜åŒ–å™¨åç§°
            optimizer_name = dir_name.replace('checkpoints_', '').upper()
            labels.append(optimizer_name)
            print(f"âœ“ æ‰¾åˆ°: {optimizer_name} - {best_model_path}")
    
    if not checkpoint_paths:
        print("\næœªæ‰¾åˆ°ä»»ä½• best_model.pth æ–‡ä»¶")
        return
    
    print(f"\nå…±æ‰¾åˆ° {len(checkpoint_paths)} ä¸ªä¼˜åŒ–å™¨çš„è®­ç»ƒç»“æœ")
    print("\nå¼€å§‹ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    compare_models(
        checkpoint_paths,
        labels,
        save_path='optimizer_comparison.png'
    )
    
    print("\nâœ… å¯¹æ¯”å›¾å·²ä¿å­˜: optimizer_comparison.png")
    
    # ==================== 2. ç”Ÿæˆå•ç‹¬è®­ç»ƒæ›²çº¿ ====================
    print("\n" + "="*60)
    print("[2/5] ç”Ÿæˆå„ä¼˜åŒ–å™¨çš„è®­ç»ƒæ›²çº¿...")
    print("="*60)
    for dir_name in sorted(checkpoint_dirs):
        best_model_path = os.path.join(dir_name, 'best_model.pth')
        if os.path.exists(best_model_path):
            optimizer_name = dir_name.replace('checkpoints_', '')
            plot_dir = os.path.join(dir_name, 'plots')
            print(f"  {optimizer_name.upper()}: {plot_dir}/training_history.png")
            load_and_plot_checkpoint(best_model_path, save_dir=plot_dir)
    
    # ==================== 3. ç”Ÿæˆå­¦ä¹ ç‡æ›²çº¿ï¼ˆæ¯ä¸ªä¼˜åŒ–å™¨ï¼‰ ====================
    if include_lr_schedule and checkpoint_paths:
        print("\n" + "="*60)
        print("[3/6] ç”Ÿæˆå„ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡æ›²çº¿...")
        print("="*60)
        
        for path, label in zip(checkpoint_paths, labels):
            optimizer_name = label.split()[0].lower()
            checkpoint_dir = os.path.dirname(path)
            plot_dir = os.path.join(checkpoint_dir, 'plots')
            os.makedirs(plot_dir, exist_ok=True)
            
            try:
                checkpoint = torch.load(path, map_location='cpu')
                if 'learning_rates' in checkpoint:
                    learning_rates = checkpoint['learning_rates']
                    epochs_completed = len(learning_rates)
                    
                    import matplotlib.pyplot as plt
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.plot(range(1, epochs_completed + 1), learning_rates, linewidth=2)
                    ax.set_xlabel('Epoch', fontsize=12)
                    ax.set_ylabel('Learning Rate', fontsize=12)
                    ax.set_title(f'Learning Rate Schedule - {label}', fontsize=14, fontweight='bold')
                    ax.grid(True, alpha=0.3)
                    plt.tight_layout()
                    
                    lr_path = os.path.join(plot_dir, 'lr_schedule.png')
                    plt.savefig(lr_path, dpi=300, bbox_inches='tight')
                    plt.close()
                    
                    print(f"  {label}: {lr_path}")
                else:
                    print(f"  {label}: âš ï¸  checkpointä¸­æ²¡æœ‰learning_ratesæ•°æ®ï¼ˆéœ€è¦é‡æ–°è®­ç»ƒï¼‰")
            except Exception as e:
                print(f"  {label}: âš ï¸  ç”Ÿæˆå¤±è´¥: {e}")
    
    # ==================== 4. ç”Ÿæˆæ··æ·†çŸ©é˜µ ====================
    if include_confusion:
        print("\n" + "="*60)
        print("[4/6] ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
        print("="*60)
        
        try:
            # åŠ è½½æµ‹è¯•é›†
            print("  åŠ è½½æµ‹è¯•æ•°æ®...")
            data_loader = CIFAR10DataLoader(
                data_dir='./data',
                batch_size=128,
                num_workers=4,
                use_cutout=False
            )
            test_loader = data_loader.get_test_loader()
            
            # å®šä¹‰ç±»åˆ«åç§°
            classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                      'dog', 'frog', 'horse', 'ship', 'truck']
            
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # ä¸ºæ¯ä¸ªä¼˜åŒ–å™¨ç”Ÿæˆæ··æ·†çŸ©é˜µ
            for dir_name in sorted(checkpoint_dirs):
                best_model_path = os.path.join(dir_name, 'best_model.pth')
                if os.path.exists(best_model_path):
                    optimizer_name = dir_name.replace('checkpoints_', '')
                    plot_dir = os.path.join(dir_name, 'plots')
                    confusion_path = os.path.join(plot_dir, 'confusion_matrix.png')
                    
                    print(f"  {optimizer_name.upper()}: ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
                    
                    # åŠ è½½æ¨¡å‹
                    model = create_model('wideresnet28_10', num_classes=10, dropout_rate=0.0, device=device)
                    checkpoint = torch.load(best_model_path, map_location=device)
                    
                    # å¤„ç†DataParallelä¿å­˜çš„æ¨¡å‹
                    state_dict = checkpoint['model_state_dict']
                    if list(state_dict.keys())[0].startswith('module.'):
                        from collections import OrderedDict
                        new_state_dict = OrderedDict()
                        for k, v in state_dict.items():
                            new_state_dict[k[7:]] = v
                        state_dict = new_state_dict
                    
                    model.load_state_dict(state_dict)
                    
                    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
                    plot_confusion_matrix(
                        model, test_loader, classes,
                        device=device,
                        save_path=confusion_path
                    )
                    print(f"    âœ… {confusion_path}")
            
            print("âœ… æ‰€æœ‰æ··æ·†çŸ©é˜µå·²ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆæ··æ·†çŸ©é˜µå¤±è´¥: {e}")
            print("   è·³è¿‡æ··æ·†çŸ©é˜µç”Ÿæˆ")
    
    # ==================== 5. ç”Ÿæˆå­¦ä¹ ç‡è°ƒåº¦æ›²çº¿ç¤ºä¾‹å’Œæ•°æ®å¢å¼ºå¯è§†åŒ– ====================
    if include_extra:
        print("\n" + "="*60)
        print("[5/6] ç”Ÿæˆé¢å¤–å¯è§†åŒ–ï¼ˆç¤ºä¾‹å›¾ï¼‰...")
        print("="*60)
        
        # ç»˜åˆ¶å››ä¸ªä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡æ›²çº¿å¯¹æ¯”å›¾
        if include_lr_schedule:
            try:
                print("  ç»˜åˆ¶å››ä¸ªä¼˜åŒ–å™¨å­¦ä¹ ç‡å¯¹æ¯”æ›²çº¿...")
                import matplotlib.pyplot as plt
                
                # æ”¶é›†æ‰€æœ‰ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡æ•°æ®
                lr_data = {}
                for path, label in zip(checkpoint_paths, labels):
                    try:
                        checkpoint = torch.load(path, map_location='cpu')
                        if 'learning_rates' in checkpoint:
                            lr_data[label] = checkpoint['learning_rates']
                            print(f"    âœ“ {label}: æ‰¾åˆ° {len(checkpoint['learning_rates'])} ä¸ªepochæ•°æ®")
                        else:
                            print(f"    âœ— {label}: æ— learning_rates")
                    except Exception as e:
                        print(f"    âœ— {label}: è¯»å–å¤±è´¥ - {str(e)[:50]}")
                
                if len(lr_data) > 0:
                    # è¾“å‡ºå­¦ä¹ ç‡ç»Ÿè®¡ä¿¡æ¯
                    print("\n  å­¦ä¹ ç‡æ•°æ®ç»Ÿè®¡:")
                    for label, lrs in lr_data.items():
                        print(f"    {label}: åˆå§‹={lrs[0]:.6f}, æœ€ç»ˆ={lrs[-1]:.6e}, æœ€å¤§={max(lrs):.6f}, æœ€å°={min(lrs):.6e}")
                    
                    # åœ¨ä¸€ä¸ªå›¾è¡¨é‡Œç»˜åˆ¶æ‰€æœ‰å­¦ä¹ ç‡æ›²çº¿
                    fig, ax = plt.subplots(figsize=(12, 7))
                    colors = ['#E74C3C', '#3498DB', '#2ECC71', '#F39C12']  # çº¢è“ç»¿æ©™
                    linestyles = ['-', '--', '-.', ':']  # ä¸åŒçº¿å‹ä»¥åŒºåˆ†é‡å æ›²çº¿
                    markers = ['o', 's', '^', 'D']  # ä¸åŒæ ‡è®°ç‚¹
                    
                    for idx, (label, learning_rates) in enumerate(lr_data.items()):
                        epochs = range(1, len(learning_rates) + 1)
                        color = colors[idx % len(colors)]
                        linestyle = linestyles[idx % len(linestyles)]
                        marker = markers[idx % len(markers)]
                        
                        # æ¯éš”20ä¸ªepochæ˜¾ç¤ºä¸€ä¸ªæ ‡è®°ç‚¹ï¼Œé¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤
                        markevery = max(1, len(learning_rates) // 10)
                        
                        ax.plot(epochs, learning_rates, linewidth=3.0, 
                               label=label, color=color, alpha=0.9, 
                               linestyle=linestyle, marker=marker, 
                               markersize=8, markevery=markevery, markerfacecolor='white',
                               markeredgewidth=2, markeredgecolor=color)
                    
                    ax.set_xlabel('Epoch', fontsize=13, fontweight='bold')
                    ax.set_ylabel('Learning Rate', fontsize=13, fontweight='bold')
                    ax.set_title('Learning Rate Schedule Comparison', 
                                fontsize=15, fontweight='bold', pad=15)
                    ax.legend(fontsize=11, loc='upper right', framealpha=0.95)
                    ax.grid(True, alpha=0.3, linestyle='--')
                    ax.set_yscale('log')
                    plt.tight_layout()
                    
                    plt.savefig('lr_schedule_cosine.png', dpi=300, bbox_inches='tight')
                    plt.close()
                    print(f"    âœ… lr_schedule_cosine.png (åŒ…å« {len(lr_data)} æ¡æ›²çº¿)")
                else:
                    print(f"    âš ï¸  å­¦ä¹ ç‡æ•°æ®ä¸è¶³4ä¸ªä¼˜åŒ–å™¨ (æ‰¾åˆ°{len(lr_data)}ä¸ª)")
            except Exception as e:
                print(f"    âš ï¸  ç»˜åˆ¶å­¦ä¹ ç‡å¯¹æ¯”å›¾å¤±è´¥: {e}")
        
        # æ•°æ®å¢å¼ºå¯è§†åŒ–
        if include_augmentation:
            try:
                print("  ç”Ÿæˆæ•°æ®å¢å¼ºå¯è§†åŒ–...")
                data_loader = CIFAR10DataLoader(
                    data_dir='./data',
                    batch_size=128,
                    num_workers=4,
                    use_cutout=True
                )
                train_loader, _ = data_loader.get_train_valid_loader()
                
                visualize_augmentations(
                    train_loader.dataset,
                    num_samples=8,
                    save_path='data_augmentation.png'
                )
                print("    âœ… data_augmentation.png")
            except Exception as e:
                print(f"    âš ï¸  ç”Ÿæˆæ•°æ®å¢å¼ºå¯è§†åŒ–å¤±è´¥: {e}")
    
    # ==================== 6. ç”ŸæˆOptunaè°ƒå‚ç»“æœå¯è§†åŒ– ====================
    if include_optuna:
        print("\n" + "="*60)
        print("[6/6] ç”ŸæˆOptunaè°ƒå‚ç»“æœå¯è§†åŒ–...")
        print("="*60)
        
        try:
            from optuna_tools.optuna_visualize import OptunaVisualizer
            
            # æŸ¥æ‰¾æ‰€æœ‰optunaç»“æœç›®å½•
            optuna_results_dir = 'optuna_results'
            if os.path.exists(optuna_results_dir):
                optuna_dirs = glob.glob(os.path.join(optuna_results_dir, '*_optuna_*'))
                
                if optuna_dirs:
                    print(f"  æ‰¾åˆ° {len(optuna_dirs)} ä¸ªOptunaè°ƒå‚ç»“æœ")
                    
                    for optuna_dir in sorted(optuna_dirs):
                        optimizer_name = os.path.basename(optuna_dir).split('_optuna_')[0].upper()
                        print(f"\n  {optimizer_name}: ç”Ÿæˆå¯è§†åŒ–...")
                        
                        try:
                            visualizer = OptunaVisualizer(optuna_dir)
                            visualizer.generate_report()
                            
                            viz_dir = os.path.join(optuna_dir, 'visualizations')
                            print(f"    âœ… {viz_dir}/optimization_history.png")
                            print(f"    âœ… {viz_dir}/param_importance.png")
                            print(f"    âœ… {viz_dir}/param_distributions.png")
                        except Exception as e:
                            print(f"    âš ï¸  ç”Ÿæˆå¤±è´¥: {e}")
                    
                    print("\nâœ… Optunaå¯è§†åŒ–å·²ç”Ÿæˆ")
                else:
                    print("  æœªæ‰¾åˆ°Optunaè°ƒå‚ç»“æœ")
            else:
                print("  æœªæ‰¾åˆ°optuna_resultsç›®å½•")
        except ImportError:
            print("  âš ï¸  æ— æ³•å¯¼å…¥optuna_visualizeæ¨¡å—")
        except Exception as e:
            print(f"  âš ï¸  ç”ŸæˆOptunaå¯è§†åŒ–å¤±è´¥: {e}")
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "="*60)
    print("æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    print("="*60)
    print("\nğŸ“Š ç”Ÿæˆçš„å›¾è¡¨:")
    print("\n  å…¨å±€å¯¹æ¯”å›¾:")
    print("    â€¢ optimizer_comparison.png - ä¼˜åŒ–å™¨æ€§èƒ½å¯¹æ¯”")
    if include_lr_schedule:
        print("    â€¢ lr_schedule_cosine.png - å­¦ä¹ ç‡è°ƒåº¦æ›²çº¿ï¼ˆ4ä¸ªä¼˜åŒ–å™¨å¯¹æ¯”ï¼‰")
    if include_augmentation:
        print("    â€¢ data_augmentation.png - æ•°æ®å¢å¼ºæ•ˆæœ")
    
    print("\n  å„ä¼˜åŒ–å™¨è®­ç»ƒå›¾è¡¨:")
    for dir_name in sorted(checkpoint_dirs):
        optimizer_name = dir_name.replace('checkpoints_', '').upper()
        plot_dir = os.path.join(dir_name, 'plots')
        print(f"\n  {optimizer_name}:")
        print(f"    â€¢ {plot_dir}/training_history.png - è®­ç»ƒæ›²çº¿")
        if include_confusion:
            confusion_path = os.path.join(plot_dir, 'confusion_matrix.png')
            if os.path.exists(confusion_path):
                print(f"    â€¢ {plot_dir}/confusion_matrix.png - æ··æ·†çŸ©é˜µ")
    
    # æ˜¾ç¤ºOptunaç»“æœ
    if include_optuna:
        optuna_results_dir = 'optuna_results'
        if os.path.exists(optuna_results_dir):
            optuna_dirs = glob.glob(os.path.join(optuna_results_dir, '*_optuna_*'))
            if optuna_dirs:
                print("\n  Optunaè°ƒå‚ç»“æœ:")
                for optuna_dir in sorted(optuna_dirs):
                    optimizer_name = os.path.basename(optuna_dir).split('_optuna_')[0].upper()
                    viz_dir = os.path.join(optuna_dir, 'visualizations')
                    if os.path.exists(viz_dir):
                        print(f"\n  {optimizer_name} (Optuna):")
                        print(f"    â€¢ {viz_dir}/optimization_history.png")
                        print(f"    â€¢ {viz_dir}/param_importance.png")
                        print(f"    â€¢ {viz_dir}/param_distributions.png")
                        print(f"    â€¢ {viz_dir}/summary.txt")
    
    print("\n" + "="*60)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ‰€æœ‰è®­ç»ƒç»“æœå¯è§†åŒ–')
    parser.add_argument('--no-confusion', action='store_true',
                       help='ä¸ç”Ÿæˆæ··æ·†çŸ©é˜µï¼ˆè·³è¿‡åŠ è½½æ¨¡å‹å’Œæµ‹è¯•é›†ï¼‰')
    parser.add_argument('--no-extra', action='store_true',
                       help='åªç”ŸæˆåŸºç¡€å›¾è¡¨ï¼ˆè®­ç»ƒæ›²çº¿å’Œå¯¹æ¯”å›¾ï¼‰')
    parser.add_argument('--no-lr', action='store_true',
                       help='ä¸ç”Ÿæˆå­¦ä¹ ç‡è°ƒåº¦æ›²çº¿')
    parser.add_argument('--no-aug', action='store_true',
                       help='ä¸ç”Ÿæˆæ•°æ®å¢å¼ºå¯è§†åŒ–')
    parser.add_argument('--no-optuna', action='store_true',
                       help='ä¸ç”ŸæˆOptunaè°ƒå‚ç»“æœå¯è§†åŒ–')
    
    args = parser.parse_args()
    
    plot_all_results(
        include_extra=not args.no_extra,
        include_confusion=not args.no_confusion,
        include_lr_schedule=not args.no_lr,
        include_augmentation=not args.no_aug,
        include_optuna=not args.no_optuna
    )
