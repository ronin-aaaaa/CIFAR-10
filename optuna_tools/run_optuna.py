"""
Optunaå¿«é€Ÿå¯åŠ¨è„šæœ¬
æä¾›ä¾¿æ·çš„å‘½ä»¤è¡Œæ¥å£æ¥è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–
"""
import argparse
import os
import sys

# ç¡®ä¿èƒ½å¤Ÿå¯¼å…¥optuna_configs
script_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, script_dir)

from optuna_configs import QUICK_CONFIG, FULL_CONFIG, DEEP_CONFIG, get_optimizer_config, print_optimizer_info


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Optunaè¶…å‚æ•°ä¼˜åŒ–å¿«é€Ÿå¯åŠ¨è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¿«é€Ÿæµ‹è¯•AdamWä¼˜åŒ–å™¨ï¼ˆ10æ¬¡è¯•éªŒï¼Œ50è½®è®­ç»ƒï¼‰
  python run_optuna.py --optimizer adamw --mode quick
  
  # å®Œæ•´ä¼˜åŒ–SGDä¼˜åŒ–å™¨ï¼ˆ20æ¬¡è¯•éªŒï¼Œ200è½®è®­ç»ƒï¼‰
  python run_optuna.py --optimizer sgd --mode full
  
  # æ·±åº¦ä¼˜åŒ–Adamä¼˜åŒ–å™¨ï¼ˆ30æ¬¡è¯•éªŒï¼Œ200è½®è®­ç»ƒï¼‰
  python run_optuna.py --optimizer adam --mode deep
  
  # ä¸€æ¬¡æ€§è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å™¨ï¼ˆæ¨èï¼‰
  python run_optuna.py --optimizer all --mode full
  
  # æŒ‡å®šä½¿ç”¨ç‰¹å®šGPUå¡ï¼ˆå¦‚åªç”¨å¡0å’Œå¡1ï¼‰
  python run_optuna.py --optimizer adamw --mode quick --gpu_ids 0,1
  
  # æŸ¥çœ‹ä¼˜åŒ–å™¨çš„å‚æ•°æœç´¢ç©ºé—´
  python run_optuna.py --optimizer adamw --info
  
  # è‡ªå®šä¹‰è¯•éªŒæ¬¡æ•°å’Œè®­ç»ƒè½®æ•°
  python run_optuna.py --optimizer adamw --n_trials 30 --epochs 150
        """
    )
    
    # å¿…é€‰å‚æ•°
    parser.add_argument('--optimizer', type=str, required=True,
                       choices=['sgd', 'adam', 'adamw', 'rmsprop', 'all'],
                       help='è¦ä¼˜åŒ–çš„ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨allå¯ä¸€æ¬¡æ€§è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å™¨ï¼‰')
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument('--mode', type=str, default='full',
                       choices=['quick', 'full', 'deep'],
                       help='ä¼˜åŒ–æ¨¡å¼: quick(å¿«é€Ÿæµ‹è¯•), full(å®Œæ•´ä¼˜åŒ–), deep(æ·±åº¦ä¼˜åŒ–)')
    
    # ä¿¡æ¯æŸ¥çœ‹
    parser.add_argument('--info', action='store_true',
                       help='åªæ˜¾ç¤ºä¼˜åŒ–å™¨ä¿¡æ¯ï¼Œä¸è¿è¡Œä¼˜åŒ–')
    
    # è‡ªå®šä¹‰å‚æ•°
    parser.add_argument('--n_trials', type=int, default=None,
                       help='è¯•éªŒæ¬¡æ•°ï¼ˆè¦†ç›–modeè®¾ç½®ï¼‰')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–modeè®¾ç½®ï¼‰')
    parser.add_argument('--batch_size', type=int, default=128,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--model', type=str, default='wideresnet28_10',
                       choices=['wideresnet28_10', 'wideresnet40_10'],
                       help='æ¨¡å‹æ¶æ„')
    parser.add_argument('--save_dir', type=str, default=os.path.join(os.path.dirname(script_dir), 'optuna_results'),
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--no_gpu', action='store_true',
                       help='ç¦ç”¨GPUï¼ˆä½¿ç”¨CPUè®­ç»ƒï¼‰')
    parser.add_argument('--gpu_ids', type=str, default=None,
                       help='æŒ‡å®šä½¿ç”¨çš„GPU IDï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚"0,1,2,3"')
    
    args = parser.parse_args()
    
    # å¦‚æœæ˜¯allï¼Œå¾ªç¯è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å™¨
    if args.optimizer == 'all':
        optimizers = ['sgd', 'adam', 'adamw', 'rmsprop']
        
        # è·å–é…ç½®
        if args.mode == 'quick':
            config = QUICK_CONFIG
        elif args.mode == 'full':
            config = FULL_CONFIG
        elif args.mode == 'deep':
            config = DEEP_CONFIG
        
        n_trials = args.n_trials if args.n_trials is not None else config['n_trials']
        epochs = args.epochs if args.epochs is not None else config['epochs']
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ æ‰¹é‡è¿è¡Œæ¨¡å¼ï¼šå°†ä¾æ¬¡è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å™¨")
        print(f"ä¼˜åŒ–å™¨åˆ—è¡¨: {', '.join([opt.upper() for opt in optimizers])}")
        print(f"æ¨¡å¼: {args.mode.upper()}")
        print(f"æ¯ä¸ªä¼˜åŒ–å™¨è¯•éªŒæ¬¡æ•°: {n_trials}")
        print(f"æ¯æ¬¡è®­ç»ƒè½®æ•°: {epochs}")
        print(f"{'='*80}\n")
        
        # æ‰¹é‡è¿è¡Œæ—¶åªç¡®è®¤ä¸€æ¬¡
        if args.mode in ['full', 'deep']:
            total_time_estimate = len(optimizers) * n_trials * epochs * 2 / 60
            print(f"â±ï¸  é¢„è®¡æ€»ç”¨æ—¶: ~{total_time_estimate:.1f}å°æ—¶ (4ä¸ªä¼˜åŒ–å™¨)")
            print(f"ğŸ’¡ æç¤º: å¦‚æœæƒ³å¿«é€Ÿæµ‹è¯•ï¼Œä½¿ç”¨ --mode quick")
            
            response = input("\næ˜¯å¦ç»§ç»­æ‰¹é‡è¿è¡Œ? [y/N]: ")
            if response.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return
        
        for i, opt in enumerate(optimizers, 1):
            print(f"\n{'#'*80}")
            print(f"# [{i}/{len(optimizers)}] å¼€å§‹ä¼˜åŒ–: {opt.upper()}")
            print(f"{'#'*80}\n")
            
            # åˆ›å»ºä¸´æ—¶argså¯¹è±¡
            temp_args = argparse.Namespace(**vars(args))
            temp_args.optimizer = opt
            
            # è¿è¡Œå•ä¸ªä¼˜åŒ–å™¨ï¼ˆè·³è¿‡ç¡®è®¤ï¼‰
            run_single_optimizer(temp_args, skip_confirm=True)
            
            if i < len(optimizers):
                print(f"\n{'='*80}")
                print(f"âœ… {opt.upper()} å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªä¼˜åŒ–å™¨...")
                print(f"{'='*80}\n")
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ æ‰€æœ‰ä¼˜åŒ–å™¨è°ƒå‚å®Œæˆï¼")
        print(f"{'='*80}\n")
        return
    
    # è¿è¡Œå•ä¸ªä¼˜åŒ–å™¨
    run_single_optimizer(args, skip_confirm=False)


def run_single_optimizer(args, skip_confirm=False):
    """è¿è¡Œå•ä¸ªä¼˜åŒ–å™¨çš„è°ƒå‚
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°
        skip_confirm: æ˜¯å¦è·³è¿‡ç¡®è®¤ï¼ˆæ‰¹é‡è¿è¡Œæ—¶ä½¿ç”¨ï¼‰
    """
    # å¦‚æœåªæ˜¯æŸ¥çœ‹ä¿¡æ¯
    if args.info:
        print_optimizer_info(args.optimizer)
        return
    
    # æ ¹æ®æ¨¡å¼è®¾ç½®å‚æ•°
    if args.mode == 'quick':
        config = QUICK_CONFIG
        print("\nğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    elif args.mode == 'full':
        config = FULL_CONFIG
        print("\nğŸ¯ å®Œæ•´ä¼˜åŒ–æ¨¡å¼")
    elif args.mode == 'deep':
        config = DEEP_CONFIG
        print("\nğŸ”¬ æ·±åº¦ä¼˜åŒ–æ¨¡å¼")
    
    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†è‡ªå®šä¹‰å€¼ï¼Œè¦†ç›–é…ç½®
    n_trials = args.n_trials if args.n_trials is not None else config['n_trials']
    epochs = args.epochs if args.epochs is not None else config['epochs']
    
    print(f"{'='*80}")
    print(f"ä¼˜åŒ–å™¨: {args.optimizer.upper()}")
    print(f"æ¨¡å‹: {args.model}")
    print(f"è¯•éªŒæ¬¡æ•°: {n_trials}")
    print(f"æ¯æ¬¡è®­ç»ƒè½®æ•°: {epochs}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"{'='*80}\n")
    
    # æ˜¾ç¤ºä¼˜åŒ–å™¨çš„å½“å‰æ€§èƒ½å’Œç›®æ ‡
    opt_config = get_optimizer_config(args.optimizer)
    print(f"ğŸ“Š {opt_config['description']}")
    print(f"ğŸ¯ ç›®æ ‡: {opt_config['target']}\n")
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­ï¼ˆæ‰¹é‡è¿è¡Œæ—¶è·³è¿‡ï¼‰
    if not skip_confirm and args.mode in ['full', 'deep']:
        total_time_estimate = n_trials * epochs * 2 / 60  # ç²—ç•¥ä¼°è®¡ï¼ˆåˆ†é’Ÿï¼‰
        print(f"â±ï¸  é¢„è®¡æ€»ç”¨æ—¶: ~{total_time_estimate:.1f}å°æ—¶")
        print(f"ğŸ’¡ æç¤º: å¦‚æœæƒ³å¿«é€Ÿæµ‹è¯•ï¼Œä½¿ç”¨ --mode quick")
        
        response = input("\næ˜¯å¦ç»§ç»­? [y/N]: ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    # æ„å»ºå‘½ä»¤ - ä½¿ç”¨ç»å¯¹è·¯å¾„
    optuna_script = os.path.join(script_dir, 'optuna_tuning.py')
    cmd_parts = [
        f'python "{optuna_script}"',
        f'--optimizer {args.optimizer}',
        f'--n_trials {n_trials}',
        f'--epochs {epochs}',
        f'--batch_size {args.batch_size}',
        f'--num_workers {args.num_workers}',
        f'--model {args.model}',
        f'--save_dir {args.save_dir}'
    ]
    
    if args.no_gpu:
        cmd_parts.append('--multi_gpu False')
    
    if args.gpu_ids:
        cmd_parts.append(f'--gpu_ids {args.gpu_ids}')
    
    cmd = ' '.join(cmd_parts)
    
    print(f"\næ‰§è¡Œå‘½ä»¤:")
    print(f"  {cmd}\n")
    
    # æ‰§è¡Œå‘½ä»¤
    os.system(cmd)


if __name__ == '__main__':
    main()
