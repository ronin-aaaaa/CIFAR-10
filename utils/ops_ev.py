"""
è¯„ä¼°ç±»ä»£ç 
åŒ…å«è®­ç»ƒã€æµ‹è¯•ã€æ‰¹é‡è¿è¡Œå’Œå·¥ä½œæµç¨‹ç®¡ç†
"""
import torch
import os
import time
import copy
import json
from collections import OrderedDict
from datetime import datetime, timezone, timedelta
from utils.ops_io import CIFAR10DataLoader
from utils.ops_tt import Trainer, Tester
from utils.ops_al import set_seed, create_model, get_optimizer_lr, get_optimizer_weight_decay, get_optimizer_mixup_alpha, get_optimizer_label_smoothing

TZ_CN = timezone(timedelta(hours=8))


def print_summary(results, total_duration, args):
    """
    æ‰“å°å®éªŒæ€»ç»“æŠ¥å‘Š
    
    å‚æ•°:
        results: ç»“æœåˆ—è¡¨
        total_duration: æ€»ç”¨æ—¶ï¼ˆç§’ï¼‰
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    print("\n" + "="*70)
    print("å®éªŒå®Œæˆ!")
    print("="*70)
    print(f"æ€»ç”¨æ—¶: {total_duration/3600:.2f} å°æ—¶")
    print(f"ç»“æŸæ—¶é—´: {datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nå„ä¼˜åŒ–å™¨ç»“æœ:")
    print("-" * 70)
    
    for result in results:
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
        print(f"{result['optimizer'].upper():10s} | {status:8s} | ç”¨æ—¶: {result['duration_minutes']:6.1f}åˆ†é’Ÿ", end="")
        
        if result['success']:
            if result['best_acc'] is not None:
                print(f" | éªŒè¯: {result['best_acc']:5.2f}%", end="")
            if result['test_acc'] is not None:
                print(f" | æµ‹è¯•: {result['test_acc']:5.2f}%", end="")
            print(f" | ç›®å½•: {result['save_dir']}")
        else:
            print(f" | é”™è¯¯: {result['error']}")
    
    print("-" * 70)
    
    # ä¿å­˜ç»“æœåˆ°JSON
    result_file = "optimizer_comparison.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'start_time': datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S'),
            'total_duration_hours': total_duration / 3600,
            'config': {
                'epochs': args.epochs,
                'batch_size': args.batch_size,
                'model': args.model,
                'gpu_ids': args.gpu_ids,
            },
            'results': results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {result_file}")
    
    # ä¿å­˜txtæ ¼å¼æŠ¥å‘Š
    txt_file = result_file.replace('.json', '.txt')
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("CIFAR-10 ä¼˜åŒ–å™¨å¯¹æ¯”å®éªŒæŠ¥å‘Š\n")
        f.write("="*70 + "\n\n")
        
        f.write(f"å¼€å§‹æ—¶é—´: {datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»ç”¨æ—¶: {total_duration/3600:.2f} å°æ—¶\n\n")
        
        f.write("å®éªŒé…ç½®:\n")
        f.write(f"  è®­ç»ƒè½®æ•°: {args.epochs}\n")
        f.write(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}\n")
        f.write(f"  æ¨¡å‹: {args.model}\n")
        f.write(f"  GPU: {args.gpu_ids}\n\n")
        
        f.write("-"*70 + "\n")
        header = "  ä¼˜åŒ–å™¨   |   çŠ¶æ€   |      ç”¨æ—¶      |   éªŒè¯å‡†ç¡®ç‡   |   æµ‹è¯•å‡†ç¡®ç‡\n"
        f.write(header)
        f.write("-"*70 + "\n")
        
        for result in results:
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
            optimizer = result['optimizer'].upper()
            duration = f"{result['duration_minutes']:.1f}åˆ†é’Ÿ"
            
            if result['success']:
                best_acc = f"{result['best_acc']:.2f}%" if result['best_acc'] else "N/A"
                test_acc = f"{result['test_acc']:.2f}%" if result['test_acc'] else "N/A"
                f.write(f"{optimizer:^10} | {status:^8} | {duration:^15} | {best_acc:^12} | {test_acc:^12}\n")
            else:
                f.write(f"{optimizer:^10} | {status:^8} | {duration:^15} | N/A          | N/A\n")
                f.write(f"  é”™è¯¯: {result['error']}\n")
        
        f.write("-"*70 + "\n")
        
        # æœ€ä½³ä¼˜åŒ–å™¨
        successful_results = [r for r in results if r['success']]
        if successful_results:
            if args.mode in ['both', 'test'] and any(r['test_acc'] for r in successful_results):
                best_result = max([r for r in successful_results if r['test_acc']], 
                                key=lambda x: x['test_acc'])
                f.write(f"\nğŸ† æœ€ä½³ä¼˜åŒ–å™¨ (æµ‹è¯•é›†): {best_result['optimizer'].upper()} - {best_result['test_acc']:.2f}%\n")
            elif args.mode in ['both', 'train'] and any(r['best_acc'] for r in successful_results):
                best_result = max([r for r in successful_results if r['best_acc']], 
                                key=lambda x: x['best_acc'])
                f.write(f"\nğŸ† æœ€ä½³ä¼˜åŒ–å™¨ (éªŒè¯é›†): {best_result['optimizer'].upper()} - {best_result['best_acc']:.2f}%\n")
        
        f.write("\n" + "="*70 + "\n")
        f.write("å®éªŒå®Œæˆ!\n")
    
    print(f"TXTæŠ¥å‘Šå·²ä¿å­˜è‡³: {txt_file}")
    
    # æ‰¾å‡ºæœ€ä½³ä¼˜åŒ–å™¨
    successful_results = [r for r in results if r['success']]
    if successful_results:
        if args.mode in ['both', 'test'] and any(r['test_acc'] for r in successful_results):
            best_result = max([r for r in successful_results if r['test_acc']], 
                            key=lambda x: x['test_acc'])
            print(f"\nğŸ† æœ€ä½³ä¼˜åŒ–å™¨ (æµ‹è¯•é›†): {best_result['optimizer'].upper()} - {best_result['test_acc']:.2f}%")
        elif args.mode in ['both', 'train'] and any(r['best_acc'] for r in successful_results):
            best_result = max([r for r in successful_results if r['best_acc']], 
                            key=lambda x: x['best_acc'])
            print(f"\nğŸ† æœ€ä½³ä¼˜åŒ–å™¨ (éªŒè¯é›†): {best_result['optimizer'].upper()} - {best_result['best_acc']:.2f}%")
    
    print("\nğŸ‰ æ‰€æœ‰ä¼˜åŒ–å™¨å®éªŒå®Œæˆ!")
    
    # è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    print("\n" + "="*70)
    print("æ­£åœ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    print("="*70)
    try:
        from utils.ops_viz import compare_models
        
        checkpoint_paths = []
        plot_labels = []
        for result in successful_results:
            checkpoint_path = f"{result['save_dir']}/best_model.pth"
            if os.path.exists(checkpoint_path):
                checkpoint_paths.append(checkpoint_path)
                plot_labels.append(result['optimizer'].upper())
        
        if checkpoint_paths:
            compare_models(checkpoint_paths, plot_labels, 'optimizer_comparison.png')
            print("\nâœ… å¯¹æ¯”å›¾å·²ä¿å­˜: optimizer_comparison.png")
    except Exception as e:
        print(f"\nâš ï¸  ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {e}")
        print("   å¯æ‰‹åŠ¨è¿è¡Œ: python plot_results.py")


def train_model(args):
    """è®­ç»ƒæ¨¡å‹"""
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # å¤šGPUé…ç½®
    use_multi_gpu = False
    gpu_ids = None
    
    if args.multi_gpu and torch.cuda.is_available():
        # è§£æGPU IDs
        if args.gpu_ids:
            gpu_ids = [int(x.strip()) for x in args.gpu_ids.split(',')]
        else:
            # è‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            gpu_ids = list(range(torch.cuda.device_count()))
        
        if len(gpu_ids) > 1:
            use_multi_gpu = True
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŒ‡å®šçš„GPUä½œä¸ºä¸»è®¾å¤‡
            device = torch.device(f'cuda:{gpu_ids[0]}')
            print(f"\nå¤šGPUè®­ç»ƒæ¨¡å¼")
            print(f"æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªå¯ç”¨GPU")
            print(f"ä½¿ç”¨GPU: {gpu_ids}")
            print(f"ä¸»è®¾å¤‡: cuda:{gpu_ids[0]}")
            for gpu_id in gpu_ids:
                print(f"  GPU {gpu_id}: {torch.cuda.get_device_name(gpu_id)}")
            # è®¡ç®—æ€»æ‰¹æ¬¡å¤§å°ï¼ˆä½¿ç”¨å±€éƒ¨å˜é‡ï¼Œä¸ä¿®æ”¹argsï¼‰
            per_gpu_batch_size = args.batch_size
            total_batch_size = per_gpu_batch_size * len(gpu_ids)
            print(f"æ€»æ‰¹æ¬¡å¤§å°: {total_batch_size} ({per_gpu_batch_size} Ã— {len(gpu_ids)} GPUs)")
        else:
            device = torch.device(f'cuda:{gpu_ids[0]}' if gpu_ids else 'cuda')
            print(f"\nåªæœ‰ä¸€ä¸ªGPUå¯ç”¨ï¼Œä½¿ç”¨å•GPUæ¨¡å¼")
            print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    else:
        device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
        print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nåŠ è½½æ•°æ®é›†...")
    data_loader = CIFAR10DataLoader(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        use_cutout=args.use_cutout,
        validation_split=args.validation_split
    )
    
    train_loader, valid_loader = data_loader.get_train_valid_loader()
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.sampler)}")
    print(f"éªŒè¯é›†å¤§å°: {len(valid_loader.sampler)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(args.model, num_classes=10, dropout_rate=args.dropout, device=device)
    
    # å¦‚æœå¯ç”¨å¤šGPUï¼ŒåŒ…è£…ä¸ºDataParallel
    if use_multi_gpu:
        print(f"\nä½¿ç”¨DataParallelåŒ…è£…æ¨¡å‹...")
        model = torch.nn.DataParallel(model, device_ids=gpu_ids)
        print(f"æ¨¡å‹å·²åˆ†å¸ƒåˆ° {len(gpu_ids)} ä¸ªGPUä¸Š")
    # è‡ªåŠ¨è·å–ä¼˜åŒ–å™¨å¯¹åº”çš„æœ€ä½³å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡
    use_optuna = getattr(args, 'use_optuna', True)
    learning_rate = get_optimizer_lr(args.optimizer, args.lr, use_optuna)
    weight_decay = get_optimizer_weight_decay(args.optimizer, args.weight_decay, use_optuna)
    
    print(f"\nä¼˜åŒ–å™¨: {args.optimizer.upper()}")
    print(f"å­¦ä¹ ç‡: {learning_rate}" + (" (è‡ªåŠ¨é…ç½®)" if args.lr is None else " (ç”¨æˆ·æŒ‡å®š)"))
    print(f"æƒé‡è¡°å‡: {weight_decay}" + (" (è‡ªåŠ¨é…ç½®)" if args.weight_decay is None else " (ç”¨æˆ·æŒ‡å®š)"))
    
    use_optuna_mixup = args.lr is None and args.weight_decay is None
    if use_optuna_mixup and use_optuna:
        mixup_alpha = get_optimizer_mixup_alpha(args.optimizer, None, use_optuna)
        label_smoothing = get_optimizer_label_smoothing(args.optimizer, None, use_optuna)
    else:
        mixup_alpha = args.mixup_alpha
        label_smoothing = args.label_smoothing
        
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    log_file = os.path.join(args.save_dir, 'training_log.txt')
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        valid_loader=valid_loader,
        device=device,
        optimizer_name=args.optimizer,
        learning_rate=learning_rate,
        weight_decay=weight_decay,
        epochs=args.epochs,
        use_mixup=args.use_mixup,
        mixup_alpha=mixup_alpha,
        label_smoothing=label_smoothing,
        scheduler_type=args.scheduler,
        log_file=log_file
    )
    
    # å¦‚æœæŒ‡å®šäº†æ¢å¤è·¯å¾„ï¼ŒåŠ è½½æ£€æŸ¥ç‚¹
    if args.resume:
        if os.path.isfile(args.resume):
            print(f"\nä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
            checkpoint = torch.load(args.resume, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            trainer.best_acc = checkpoint.get('best_acc', 0.0)
            print(f"å·²åŠ è½½æ£€æŸ¥ç‚¹ (æœ€ä½³å‡†ç¡®ç‡: {trainer.best_acc:.2f}%)")
    # å¼€å§‹è®­ç»ƒ
    best_acc = trainer.train(save_path=args.save_dir)
    return best_acc


def test_model(args):
    """æµ‹è¯•æ¨¡å‹"""
    # å¤šGPUé…ç½®
    use_multi_gpu = False
    gpu_ids = None
    
    if args.multi_gpu and torch.cuda.is_available():
        if args.gpu_ids:
            gpu_ids = [int(x.strip()) for x in args.gpu_ids.split(',')]
        else:
            gpu_ids = list(range(torch.cuda.device_count()))
        
        if len(gpu_ids) > 1:
            use_multi_gpu = True
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŒ‡å®šçš„GPUä½œä¸ºä¸»è®¾å¤‡
            device = torch.device(f'cuda:{gpu_ids[0]}')
            print(f"\nå¤šGPUæµ‹è¯•æ¨¡å¼")
            print(f"ä½¿ç”¨GPU: {gpu_ids}")
            print(f"ä¸»è®¾å¤‡: cuda:{gpu_ids[0]}")
        else:
            device = torch.device(f'cuda:{gpu_ids[0]}' if gpu_ids else 'cuda')
            print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    else:
        device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
        print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nåŠ è½½æµ‹è¯•é›†...")
    data_loader = CIFAR10DataLoader(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        use_cutout=False  # æµ‹è¯•æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
    )
    
    test_loader = data_loader.get_test_loader()
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(args.model, num_classes=10, dropout_rate=args.dropout, device=device)
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_model_path = os.path.join(args.save_dir, 'best_model.pth')
    if os.path.isfile(best_model_path):
        print(f"\nåŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}")
        checkpoint = torch.load(best_model_path, map_location=device)
        
        # å¤„ç†DataParallelä¿å­˜çš„æ¨¡å‹
        state_dict = checkpoint['model_state_dict']
        # å¦‚æœæ˜¯DataParallelä¿å­˜çš„ï¼Œéœ€è¦å…ˆåŠ è½½åˆ°åŸå§‹æ¨¡å‹
        if list(state_dict.keys())[0].startswith('module.'):
            # ç§»é™¤'module.'å‰ç¼€
            new_state_dict = OrderedDict()
            for k, v in state_dict.items():
                name = k[7:]  # ç§»é™¤'module.'
                new_state_dict[name] = v
            state_dict = new_state_dict
        
        model.load_state_dict(state_dict)
        print(f"æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%")
    else:
        print(f"\nè­¦å‘Š: æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ {best_model_path}")
        print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
    
    # å¦‚æœå¯ç”¨å¤šGPUï¼ŒåŒ…è£…ä¸ºDataParallel
    if use_multi_gpu:
        print(f"\nä½¿ç”¨DataParallelåŒ…è£…æ¨¡å‹...")
        model = torch.nn.DataParallel(model, device_ids=gpu_ids)
        print(f"æ¨¡å‹å·²åˆ†å¸ƒåˆ° {len(gpu_ids)} ä¸ªGPUä¸Š")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = Tester(model=model, test_loader=test_loader, device=device)
    
    # æµ‹è¯•æ¨¡å‹ï¼ˆå¹¶ä¿å­˜æµ‹è¯•ç»“æœåˆ°training_summary.txtï¼‰
    test_acc = tester.test(save_path=args.save_dir)
    return test_acc


def run_single_optimizer(optimizer, args, get_optimizer_lr_func, train_func, test_func):
    """è¿è¡Œå•ä¸ªä¼˜åŒ–å™¨çš„è®­ç»ƒå’Œæµ‹è¯•"""
    # åˆ›å»ºä¼˜åŒ–å™¨ä¸“å±çš„ä¿å­˜ç›®å½•
    optimizer_save_dir = f"{args.save_dir.rstrip('/')}_{optimizer}"

    # å¤åˆ¶å‚æ•°å¹¶ä¿®æ”¹ä¼˜åŒ–å™¨å’Œä¿å­˜ç›®å½•
    optimizer_args = copy.deepcopy(args)
    optimizer_args.optimizer = optimizer
    optimizer_args.save_dir = optimizer_save_dir

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(optimizer_save_dir, exist_ok=True)

    # æ˜¾ç¤ºé…ç½®
    print(f"\nä¼˜åŒ–å™¨: {optimizer.upper()}")
    print(f"ä¿å­˜ç›®å½•: {optimizer_save_dir}")
    learning_rate = get_optimizer_lr_func(optimizer, args.lr)
    print(f"å­¦ä¹ ç‡: {learning_rate} (è‡ªåŠ¨é…ç½®)")
    print()
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # è¿è¡Œè®­ç»ƒ
        if args.mode == 'train':
            best_acc = train_func(optimizer_args)
            test_acc = None
        elif args.mode == 'test':
            test_acc = test_func(optimizer_args)
            best_acc = None
        else:  # both
            best_acc = train_func(optimizer_args)
            test_acc = test_func(optimizer_args)
        
        duration = time.time() - start_time
        success = True
        error_msg = None
        
        print(f"\nâœ… {optimizer.upper()} å®Œæˆ! ç”¨æ—¶: {duration/60:.1f} åˆ†é’Ÿ")
        if best_acc is not None:
            print(f"   éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:.2f}%")
        if test_acc is not None:
            print(f"   æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.2f}%")
            
    except Exception as e:
        duration = time.time() - start_time
        success = False
        error_msg = str(e)
        best_acc = None
        test_acc = None
        print(f"\nâŒ {optimizer.upper()} è®­ç»ƒå¤±è´¥: {error_msg}")
    
    return {
        'optimizer': optimizer,
        'success': success,
        'duration_minutes': duration / 60,
        'best_acc': best_acc,
        'test_acc': test_acc,
        'save_dir': optimizer_save_dir,
        'error': error_msg
    }


def run_all_optimizers_batch(args, get_optimizer_lr_func, train_func, test_func, optimizers=None):
    """æ‰¹é‡è¿è¡Œæ‰€æœ‰æ”¯æŒçš„ä¼˜åŒ–å™¨"""
    if optimizers is None:
        optimizers = ['sgd', 'adam', 'adamw', 'rmsprop']  # é»˜è®¤ä¼˜åŒ–å™¨åˆ—è¡¨
    
    print("\n" + "="*70)
    print("CIFAR-10 ä¼˜åŒ–å™¨å¯¹æ¯”å®éªŒ")
    print("="*70)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nå°†ä¾æ¬¡è®­ç»ƒä»¥ä¸‹ä¼˜åŒ–å™¨: {', '.join([opt.upper() for opt in optimizers])}")
    print(f"æ¯ä¸ªä¼˜åŒ–å™¨è®­ç»ƒ {args.epochs} è½®")
    print(f"é¢„è®¡æ€»æ—¶é•¿: {len(optimizers) * args.epochs / 200 * 1:.1f}-{len(optimizers) * args.epochs / 200 * 1.5:.1f} å°æ—¶")
    print("="*70)

    # åˆ›å»ºæ•°æ®ç›®å½•
    os.makedirs(args.data_dir, exist_ok=True)
    results = []
    total_start_time = time.time()
    
    # ä¾æ¬¡è¿è¡Œæ¯ä¸ªä¼˜åŒ–å™¨
    for i, optimizer in enumerate(optimizers, 1):
        print(f"\n{'='*70}")
        print(f"[{i}/{len(optimizers)}] å¼€å§‹è®­ç»ƒ: {optimizer.upper()}")
        print(f"{'='*70}")
        result = run_single_optimizer(optimizer, args, get_optimizer_lr_func, train_func, test_func)
        results.append(result)
        
        # æ˜¾ç¤ºè¿›åº¦
        completed = sum(1 for r in results if r['success'])
        print(f"\nè¿›åº¦: {len(results)}/{len(optimizers)} å®Œæˆ, {completed} æˆåŠŸ")
    
    total_duration = time.time() - total_start_time
    print_summary(results, total_duration, args)


def run_all_optimizers(args, optimizers=None):
    """è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å™¨çš„å…¥å£å‡½æ•°"""
    run_all_optimizers_batch(args, get_optimizer_lr, train_model, test_model, optimizers)


def run_single_training(args):
    """è¿è¡Œå•ä¸ªä¼˜åŒ–å™¨è®­ç»ƒ"""
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    os.makedirs(args.data_dir, exist_ok=True)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("\n" + "="*60)
    print("CIFAR-10 é«˜ç²¾åº¦åˆ†ç±»è®­ç»ƒ")
    print("="*60)
    print("\né…ç½®ä¿¡æ¯:")
    for arg in vars(args):
        print(f"  {arg}: {getattr(args, arg)}")
    print("="*60)
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == 'train':
        print("\nå¼€å§‹è®­ç»ƒæ¨¡å¼...")
        best_acc = train_model(args)
        print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
        
    elif args.mode == 'test':
        print("\nå¼€å§‹æµ‹è¯•æ¨¡å¼...")
        test_acc = test_model(args)
        print(f"\næµ‹è¯•å®Œæˆ! æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
        
    elif args.mode == 'both':
        print("\nå¼€å§‹è®­ç»ƒ+æµ‹è¯•æ¨¡å¼...")
        
        # è®­ç»ƒ
        print("\n[é˜¶æ®µ1/2] è®­ç»ƒæ¨¡å‹")
        best_acc = train_model(args)
        print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
        
        # æµ‹è¯•
        print("\n[é˜¶æ®µ2/2] æµ‹è¯•æ¨¡å‹")
        test_acc = test_model(args)
        print(f"\næµ‹è¯•å®Œæˆ! æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
        
        # æ€»ç»“
        print("\n" + "="*60)
        print("è®­ç»ƒå’Œæµ‹è¯•æ€»ç»“:")
        print(f"  éªŒè¯é›†æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
        print(f"  æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.2f}%")
    
    print("\nç¨‹åºè¿è¡Œå®Œæˆ!")
